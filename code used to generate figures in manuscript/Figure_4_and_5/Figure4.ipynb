{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure 4: moBonita identifies mechanisms of hypoxia-mediated chemotaxis in RAMOS B cells \n",
    "\n",
    "* (a) Reduction of ERS – show ERS sizes of all three datasets on one plot \n",
    "* (b) Highly modulated nodes from the dataset – modulation score vs expression scatterplot \n",
    "* (c ) Pathway analysis from all three datasets on one plot \n",
    "* (d ) Subnetworks of influential genes from PKNs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from scipy.stats import ttest_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sns.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import statsmodels.stats.multitest\n",
    "import os\n",
    "import re\n",
    "import requests\n",
    "from ast import literal_eval\n",
    "from glob import glob\n",
    "from numpy import arange\n",
    "import deap \n",
    "\n",
    "def getPathwayName(hsaURL):\n",
    "    \"\"\"Use KEGG API to get the readable name using the KEGG code (eg. hsa00010 corresponds to the glycolysis pathway)\"\"\"\n",
    "    fileReg = re.compile(\"NAME\\s+(\\w+.*)\")\n",
    "    pathwayFile = requests.get(\"http://rest.kegg.jp/get/\" + hsaURL,\n",
    "                               stream=True)\n",
    "    for line in pathwayFile.iter_lines():\n",
    "        line = line.decode(\"utf-8\")\n",
    "        result = fileReg.match(line)\n",
    "        if result:\n",
    "            return result.group(1)\n",
    "    return hsaURL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processBonitaPvalues(pvalues,\n",
    "                         adjustPvalue=True,\n",
    "                         method=[\n",
    "                             \"bonferroni\", \"sidak\", \"holm-sidak\", \"sidak\",\n",
    "                             \"simes-hochberg\", \"hommel\", \"fdr_bh\", \"fdr_by\",\n",
    "                             \"fdr_tsbh\", \"fdr_tsbky\"\n",
    "                         ],\n",
    "                         alpha=0.05, concatenated=False):\n",
    "    if concatenated:\n",
    "        pvalues = pd.read_csv(pvalues).reset_index(drop=True)\n",
    "        pvalues.columns.values[0] = 'pathway'\n",
    "        pvalues = pvalues.set_index(\"pathway\")\n",
    "    else:\n",
    "        pvalues = pd.read_csv(pvalues, index_col=0).reset_index(drop=True).set_index(\"pathway\")\n",
    "    cols = [k for k in pvalues.columns if k not in ['pathway','code','nodes', 'Pathway', 'Contrast','-log10Pvalue','Pathway Name']]\n",
    "    if adjustPvalue:\n",
    "        if concatenated:\n",
    "            for i in cols:\n",
    "                print(i)\n",
    "                print(pvalues[i])\n",
    "                pvalues[i] = statsmodels.stats.multitest.multipletests(\n",
    "                    pvalues[i].values, method=method, is_sorted=False,\n",
    "                    returnsorted=False)[1]\n",
    "                pvalues[i] = [(-1) * np.log10(j) for j in pvalues[i].values]                \n",
    "        else:\n",
    "            for i in cols:\n",
    "                print(i)\n",
    "                print(pvalues[i])\n",
    "                pvalues[i] = np.power(10, -1 * pvalues[i])\n",
    "                pvalues[i] = statsmodels.stats.multitest.multipletests(\n",
    "                    pvalues[i].values, method=method, is_sorted=False,\n",
    "                    returnsorted=False)[1]\n",
    "                pvalues[i] = [(-1) * np.log10(j) for j in pvalues[i].values]\n",
    "\n",
    "    melt_pvalues = pvalues.reset_index().melt(id_vars='pathway',\n",
    "                                              value_vars=cols)\n",
    "    melt_pvalues = melt_pvalues[melt_pvalues.value > ((-1) * np.log10(alpha))]\n",
    "    melt_pvalues = melt_pvalues.sort_values('value', ascending=False)\n",
    "    melt_pvalues.columns = (\"Pathway Name\", \"Condition\", \"value\")\n",
    "    return melt_pvalues\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pvalues = pd.read_csv(\n",
    "        \"pvalues_proteomics_20220601.csv\", index_col=0).reset_index(drop=True).set_index(\"pathway\")\n",
    "cols = [k for k in pvalues.columns if k not in ['pathway','code','nodes']]\n",
    "sns.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proteomics_pvalues = processBonitaPvalues(\n",
    "    pvalues=\"pvalues_proteomics_20220601.csv\",\n",
    "    adjustPvalue=True,\n",
    "    method='bonferroni',\n",
    "    alpha=0.001)\n",
    "#sns.set_theme(context='paper', style='ticks')\n",
    "g = sns.scatterplot(data=proteomics_pvalues,\n",
    "                    x='value',\n",
    "                    y=\"Pathway Name\",\n",
    "                    hue=\"Condition\",\n",
    "                    palette=\"Greens\",\n",
    "                    s=75)\n",
    "plt.legend(\n",
    "    loc='upper center',  #'center left',  #\n",
    "    bbox_to_anchor=(0.15, -0.15),  # (1.1, 0.6),  #\n",
    "    fancybox=True,\n",
    "    shadow=False,\n",
    "    ncol=1,\n",
    "    borderaxespad=0,\n",
    "    facecolor=\"white\")\n",
    "plt.ylabel(\"\")\n",
    "plt.xlabel(\"-log10 (adjusted p-value)\")\n",
    "axes = plt.gca()\n",
    "axes.yaxis.grid(color='grey', linestyle=(0, (5, 10)), linewidth=0.5)\n",
    "g.figure.set_figheight(8)\n",
    "g.figure.set_figwidth(5)\n",
    "g.figure.tight_layout()\n",
    "g.figure.savefig(\"proteomics_bonita.pdf\")  #, height=10, width=4)\n",
    "g.figure.savefig(\"proteomics_bonita.png\", dpi=300)  #, height=10, width=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcriptomics_pvalues = processBonitaPvalues(\n",
    "    pvalues=\"pvalues_transcriptomics_20220601.csv\",\n",
    "    adjustPvalue=False,\n",
    "    alpha=0.05)\n",
    "#sns.set_theme(context='paper', style='ticks')\n",
    "g = sns.scatterplot(data=transcriptomics_pvalues,\n",
    "                    x='value',\n",
    "                    y=\"Pathway Name\",\n",
    "                    hue=\"Condition\",\n",
    "                    palette=\"Greens\",\n",
    "                    s=75)\n",
    "plt.legend(\n",
    "    loc='upper center',  #'center left',  #\n",
    "    bbox_to_anchor=(0.15, -0.25),  # (1.1, 0.6),  #\n",
    "    fancybox=True,\n",
    "    shadow=False,\n",
    "    ncol=1,\n",
    "    borderaxespad=0,\n",
    "    facecolor=\"white\")\n",
    "plt.ylabel(\"\")\n",
    "plt.xlabel(\"-log10 (p-value)\")\n",
    "axes = plt.gca()\n",
    "axes.yaxis.grid(color='grey', linestyle=(0, (5, 10)), linewidth=0.5)\n",
    "g.figure.set_figheight(4)\n",
    "g.figure.set_figwidth(5)\n",
    "g.figure.tight_layout()\n",
    "g.figure.savefig(\"transcriptomics_bonita.pdf\")  #, height=10, width=4)\n",
    "g.figure.savefig(\"transcriptomics_bonita.png\", dpi=300)  #, height=10, width=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phosphoproteomics_pvalues = processBonitaPvalues(\n",
    "    pvalues=\"pvalues_phosphoproteomics_20220601.csv\",\n",
    "    adjustPvalue=True,\n",
    "    method='bonferroni',\n",
    "    alpha=0.05)\n",
    "#sns.set_theme(context='paper', style='ticks')\n",
    "g = sns.scatterplot(data=phosphoproteomics_pvalues,\n",
    "                    x='value',\n",
    "                    y=\"Pathway Name\",\n",
    "                    hue=\"Condition\",\n",
    "                    palette=\"Greens\",\n",
    "                    s=75)\n",
    "plt.legend(loc='upper center',\n",
    "           bbox_to_anchor=(0.15, -0.25),\n",
    "           fancybox=True,\n",
    "           shadow=False,\n",
    "           ncol=1,\n",
    "           borderaxespad=0,\n",
    "           facecolor=\"white\")\n",
    "plt.ylabel(\"\")\n",
    "plt.xlabel(\"-log10 (p-value)\")\n",
    "axes = plt.gca()\n",
    "axes.yaxis.grid(color='grey', linestyle=(0, (5, 10)), linewidth=0.5)\n",
    "g.figure.set_figheight(4)\n",
    "g.figure.set_figwidth(5)\n",
    "g.figure.tight_layout()\n",
    "g.figure.savefig(\"phosphoproteomics_bonita.pdf\")\n",
    "g.figure.savefig(\"phosphoproteomics_bonita.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_pvalues = processBonitaPvalues(\n",
    "    pvalues=\"pvalues_concatenated_20221010.csv\",\n",
    "    adjustPvalue=True,\n",
    "    alpha=0.05, concatenated=True, method = \"fdr_bh\")\n",
    "#sns.set_theme(context='paper', style='ticks')\n",
    "g = sns.scatterplot(data=concatenated_pvalues,\n",
    "                    x='value',\n",
    "                    y=\"Pathway Name\",\n",
    "                    hue=\"Condition\",\n",
    "                    palette=\"Greens\",\n",
    "                    s=75)\n",
    "plt.legend(loc='upper center',\n",
    "           bbox_to_anchor=(0.15, -0.25),\n",
    "           fancybox=True,\n",
    "           shadow=False,\n",
    "           ncol=1,\n",
    "           borderaxespad=0,\n",
    "           facecolor=\"white\")\n",
    "plt.ylabel(\"\")\n",
    "plt.xlabel(\"-log10 (p-value)\")\n",
    "axes = plt.gca()\n",
    "axes.yaxis.grid(color='grey', linestyle=(0, (5, 10)), linewidth=0.5)\n",
    "g.figure.set_figheight(4)\n",
    "g.figure.set_figwidth(5)\n",
    "g.figure.tight_layout()\n",
    "g.figure.savefig(\"concatenated_bonita.pdf\")\n",
    "g.figure.savefig(\"concatenated_bonita.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcriptomics_pvalues[\"Dataset\"] = \"Transcriptomics\"\n",
    "phosphoproteomics_pvalues[\"Dataset\"] = \"Phosphoproteomics\"\n",
    "proteomics_pvalues[\"Dataset\"] = \"Proteomics\"\n",
    "concatenated_pvalues[\"Dataset\"] = \"Concatenated\"\n",
    "all_pvalues = pd.concat(\n",
    "    [transcriptomics_pvalues, proteomics_pvalues, phosphoproteomics_pvalues, concatenated_pvalues])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     18
    ]
   },
   "outputs": [],
   "source": [
    "sns.set_theme(context='talk', style='ticks')\n",
    "g = sns.relplot(\n",
    "    data=all_pvalues,\n",
    "    x='value',\n",
    "    y=\"Pathway Name\",\n",
    "    col=\"Condition\",\n",
    "    #row=\"Dataset\",\n",
    "    hue=\"Dataset\",\n",
    "    palette=\"colorblind\",\n",
    "    s=75,\n",
    "    facet_kws={\n",
    "        'sharex': True,\n",
    "        'sharey': False,\n",
    "        'legend_out': True\n",
    "    })\n",
    "g.xlabel = \"-log10 (adjusted p-value)\"\n",
    "g.ylabel = \"\"\n",
    "g.figure.set_figheight(10)\n",
    "g.figure.set_figwidth(30)\n",
    "g.figure.tight_layout()\n",
    "\"\"\"\n",
    "for a in g.axes_dict:\n",
    "    g.axes_dict[a].yaxis.grid(color='grey', linestyle=(0, (5, 10)), linewidth=0.5)\n",
    "    g.axes_dict[a].xaxis.grid(color='grey', linestyle=(0, (5, 10)), linewidth=0.5)\n",
    "\"\"\"\n",
    "g.figure.savefig(\"all_pvalues_bonita.pdf\")\n",
    "g.figure.savefig(\"all_pvalues_bonita.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect the *local1.pickle* files in the specified directory (change directory variable below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"/gpfs/fs2/scratch/mpalshik/multiomics_networks_2022/BONITA_experiments/\"\n",
    "outputfiles = []\n",
    "for root, dirs, files in os.walk(directory):\n",
    "    for f in files:\n",
    "        if f.endswith(\"_local1.pickle\"):\n",
    "            outputfiles.append(os.path.join(root, f))\n",
    "print(len(outputfiles), outputfiles[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open local1.pickle files and process the information into a single dataframe\n",
    "**One row in the dataframe contains information for one node. The dataframe has the following columns:**\n",
    " - Network name - readable, descriptive KEGG network name\n",
    " - Method name - subfolder of the main directory in which the pickle was found\n",
    " - andNodeList - indices of parent nodes\n",
    " - andNodeInvertList - a bitstring encoding the activation and inhibition edges. True implies that the edge from the corresponding parent node in the andNodeList is an inhibitory edge\n",
    " - ruleLengths - length (ie, size) of the ERS for the node\n",
    " - equivs - bitstring representation of the equivalent rule set\n",
    " - plainRules - plain text representation of the rules in the ERS\n",
    " - randomERSIndividual - random individual from the ERS\n",
    " - minLocalSearchError - lowest error for the rules tried for each node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from utils import *\n",
    "from networkConstructor import *\n",
    "from simulation import *\n",
    "from pathway_analysis_score_pathways import *\n",
    "from pathway_analysis_score_nodes import *\n",
    "from GA import *\n",
    "# from pathway_analysis_setup import *\n",
    "import glob\n",
    "\n",
    "def findEnds2(model, node, indiv):\n",
    "    \"\"\" find the end of a node in the bitstring \"\"\"\n",
    "    node = model.nodeList.index(node)\n",
    "    if node == len(model.nodeList) - 1:\n",
    "        end1 = len(indiv)\n",
    "    else:\n",
    "        end1 = model.individualParse[node + 1]\n",
    "    start1 = model.individualParse[node]\n",
    "    return start1, end1\n",
    "\n",
    "directory = \"/gpfs/fs2/scratch/mpalshik/multiomics_networks_2022/BONITA_experiments/\"\n",
    "fileReg = re.compile('.*hsa(\\d+)\\_.+\\.pickle')\n",
    "seriesIndices = [\"networkName\", \"methodName\", \"nodeList\", \"andNodeList\", \"andNodeInvertList\", \"ruleLengths\", \"equivs\", \"plainRules\", \"randomERSIndividual\", \"minLocalSearchError\"]\n",
    "df = pd.DataFrame(columns = seriesIndices)\n",
    "i = 1\n",
    "counter = 1\n",
    "fileReg2 = re.compile(re.escape(directory) + r\"(\\w+.*)\")\n",
    "outputfiles = glob.glob(\"/gpfs/fs2/scratch/mpalshik/multiomics_networks_2022/BONITA_experiments/\"+\"*/pickles/*local1.pickle\")\n",
    "\n",
    "print(len(outputfiles))\n",
    "\n",
    "for f in outputfiles:\n",
    "    if (counter % 20 == 0):\n",
    "        print(counter)\n",
    "    counter = counter + 1\n",
    "    getMethod=fileReg2.match(f)\n",
    "    if getMethod:\n",
    "        methodName=getMethod.group(1)\n",
    "    else:\n",
    "        methodName=\"N.A.\"\n",
    "    result = fileReg.match(f)\n",
    "    networkName = getPathwayName('hsa'+result.group(1))\n",
    "    print(f)\n",
    "    outputList = pickle.load(open(f, mode = \"rb\"))\n",
    "    print(len(outputList))\n",
    "    bruteOut1,dev,storeModel, storeModel3, equivalents, dev2 = [outputList[k] for k in range(len(outputList))]\n",
    "    randomERSIndividual = bruteOut1 #random individual from the ERS\n",
    "    minLocalSearchError = dev2 #lowest error for the rules tried for each node\n",
    "    #equivalents = ERS for the network\n",
    "    #storeModel = model from the GA\n",
    "    minGAErrors = dev # minimum errors returned by the GA\n",
    "    model1=modelHolder(storeModel3) #model from the local search\n",
    "    for node in range(0,len(model1.nodeList)):\n",
    "        plainRules=[]\n",
    "        start1,end1=findEnds2(model1, model1.nodeList[node], equivalents[node])\n",
    "        ers=equivalents[node] # find the bitstring for just this node\n",
    "        #inEdges=findInEdges(model1, model1.nodeList.index(model1.nodeList[node]))\n",
    "        for rule in ers:\n",
    "            plainRules.append(writeNode(model1.nodeList.index(model1.nodeList[node]), rule, model1))\n",
    "        ruleLengths=len(ers)\n",
    "        ersAllNodes=plainRules\n",
    "        s = pd.Series([networkName, methodName, model1.nodeList[node], model1.andNodeList[node], model1.andNodeInvertList[node], ruleLengths, str(ers), plainRules, randomERSIndividual, minLocalSearchError[node]], index = seriesIndices)\n",
    "        df.loc[i] = s\n",
    "        i = i + 1\n",
    "df['methodName'] = df['methodName'].str.extract(r'(\\w+)\\/', expand=False)\n",
    "df['indegree'] = [len(set([item for sublist in literal_eval(i) for item in sublist])) for i in df.andNodeList]\n",
    "CSVfile = \"local1Data.csv\"\n",
    "dfCSVFile = open(CSVfile, mode = \"w\")\n",
    "df.to_csv(dfCSVFile)\n",
    "dfCSVFile.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"local1Data.csv\", index_col=0)\n",
    "df['indegree'] = [\n",
    "    len(set([item for sublist in literal_eval(i) for item in sublist]))\n",
    "    for i in df.andNodeList\n",
    "]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(context='talk', style='ticks', rc={'figure.figsize': (1, 1)}) #sns.set_theme\n",
    "g = sns.displot(\n",
    "    data=df[df.indegree >= 3],\n",
    "    x=\"ruleLengths\",\n",
    "    #multiple=\"stack\",\n",
    "    row=\"methodName\",\n",
    "    hue=\"methodName\",\n",
    "    palette=\"colorblind\",\n",
    "    legend=False,\n",
    "    stat=\"count\",\n",
    "    facet_kws={\n",
    "        'sharey': False,\n",
    "        'sharex': True\n",
    "    })\n",
    "g.set_axis_labels(\"Size of ERS for\\nnodes with in-degree >= 3\", \"Count\")\n",
    "g.set_titles(\"{row_name}\")\n",
    "#g.figure.figsize = (1, 1)\n",
    "g.savefig(\"figure3a.png\", dpi=300)\n",
    "g.savefig(\"figure3a.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define samples\n",
    "df2 = df[df.indegree >= 3]\n",
    "group1 = df2[df2['methodName']=='Proteomics']\n",
    "group2 = df2[df2['methodName']=='Phosphoproteomics']\n",
    "group3 = df2[df2['methodName']=='Transcriptomics']\n",
    "group4 = df2[df2['methodName']=='concatenated']\n",
    "\n",
    "#perform independent two sample t-test\n",
    "print([ttest_ind(group1['ruleLengths'], group2['ruleLengths']),\n",
    "ttest_ind(group1['ruleLengths'], group3['ruleLengths']),\n",
    "ttest_ind(group1['ruleLengths'], group4['ruleLengths']),\n",
    "ttest_ind(group2['ruleLengths'], group3['ruleLengths']),\n",
    "ttest_ind(group2['ruleLengths'], group4['ruleLengths']),\n",
    "ttest_ind(group3['ruleLengths'], group4['ruleLengths'])])\n",
    "\n",
    "print(np.mean(group1['ruleLengths']))\n",
    "print(np.mean(group2['ruleLengths']))\n",
    "print(np.mean(group3['ruleLengths']))\n",
    "print(np.mean(group4['ruleLengths']))\n",
    "\n",
    "sns.set_theme(context='talk', style='ticks', rc={'figure.figsize': (1, 1)})\n",
    "g = sns.catplot(data=df2,\n",
    "                x=\"ruleLengths\",\n",
    "                y=\"methodName\",\n",
    "                hue=\"methodName\",\n",
    "                palette=\"colorblind\",\n",
    "                legend=False,\n",
    "               kind = 'box')\n",
    "g.set_axis_labels(\"Size of ERS for\\nnodes with in-degree >= 3\", \"Dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(context='talk', style='ticks', rc={'figure.figsize': (1, 1)})\n",
    "g = sns.catplot(data=df[df.indegree >= 3],\n",
    "                x=\"ruleLengths\",\n",
    "                y=\"methodName\",\n",
    "                hue=\"methodName\",\n",
    "                palette=\"colorblind\",\n",
    "                legend=False)\n",
    "g.set_axis_labels(\"Size of ERS for\\nnodes with in-degree >= 3\", \"Dataset\")\n",
    "#g.set_titles(\"{col_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcriptomics = df[df['methodName'].str.contains('Transcriptomics')]\n",
    "print(transcriptomics.shape)\n",
    "phosphoproteomics = df[df['methodName'].str.contains('Phosphoproteomics')]\n",
    "print(phosphoproteomics.shape)\n",
    "proteomics = df[df['methodName'].str.match(\n",
    "    'Proteomics'\n",
    ")]  #note difference between contains and match - DO NOT CHANGE THIS\n",
    "print(proteomics.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get optimized networks\n",
    "def maxERS(inDegree):\n",
    "    if inDegree == 0:\n",
    "        maxERS = 1\n",
    "    else:\n",
    "        inDegree = min(inDegree, 3)\n",
    "        if inDegree == 2:\n",
    "            maxERS = 15\n",
    "        else:\n",
    "            maxERS = 127\n",
    "    return maxERS\n",
    "\n",
    "\n",
    "df.loc[:, 'maxERS'] = [maxERS(i) for i in df.indegree]\n",
    "df.loc[:, 'hasReducedERS'] = df.loc[:, 'ruleLengths'] < df.loc[:, 'maxERS']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare importance scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nodeTable = pd.DataFrame(index=[\"temp\"],\n",
    "                         columns=[\n",
    "                             \"andNode\", \"Display Name\", \"IS\", \"name\", \"RA\",\n",
    "                             \"selected\", \"shared name\", \"Dataset\", \"Contrast\",\n",
    "                             \"Network\"\n",
    "                         ])\n",
    "for file in glob(\n",
    "        \"/gpfs/fs2/scratch/mpalshik/multiomics_networks_2022/BONITA_experiments/*/*/*rules.graphml\"\n",
    "):\n",
    "    temp_df1 = pd.DataFrame(index=[\"temp\"],\n",
    "                            columns=[\n",
    "                                \"andNode\", \"Display Name\", \"IS\", \"name\", \"RA\",\"Dataset\",\n",
    "                                \"Contrast\", \"Network\"\n",
    "                            ])\n",
    "    temp_G = nx.read_graphml(file)\n",
    "    raw_table = list(temp_G.nodes.data())\n",
    "    for node in raw_table:\n",
    "        data = dict(node[1])\n",
    "        temp_df2 = pd.DataFrame(data, index=[0])\n",
    "        temp_df1 = pd.concat((temp_df1, temp_df2), axis=0)\n",
    "    temp_df1 = temp_df1.iloc[1:]\n",
    "    temp_df1 = temp_df1[temp_df1[\"andNode\"] == 0]\n",
    "    temp_df1.drop(temp_df1.columns[[0, 3, 5, 6]], axis=1, inplace=True)\n",
    "    temp_df1.index = arange(1, len(temp_df1) + 1)\n",
    "    filename = filepath = ''\n",
    "    parsed1 = file.split('/')\n",
    "    temp_df1[\"Dataset\"] = parsed1[7]\n",
    "    temp_df1[\"Contrast\"] = parsed1[8]\n",
    "    temp_df1[\"Network\"] = parsed1[9].replace(\"_rules.graphml\", \"\")\n",
    "    #parsed2 = parsed1[3:]\n",
    "    #parsed3 = parsed2[0].split(\n",
    "    #    '_')[0][:2] + '_' + parsed2[1] + '_' + parsed2[2][:-14]\n",
    "    #parsed4 = parsed3.replace('percent', '')\n",
    "    #filename = parsed4.replace('-', '_')\n",
    "    #filepath = '/'.join(parsed1[:3]) + \"/Node_Tables/\"\n",
    "    #destination = filepath + filename\n",
    "    #print(filename)\n",
    "    #temp_df1.to_csv(destination)\n",
    "    nodeTable = pd.concat([nodeTable, temp_df1])\n",
    "nodeTable = nodeTable.dropna(axis=0, how='all')\n",
    "nodeTable.to_csv(\"node_table.csv\")\n",
    "nodeTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodeTable = pd.read_csv(\"node_table.csv\", index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nt2 = nodeTable[['Display Name', 'IS', 'Dataset', 'Network']].drop_duplicates()\n",
    "nt2 = nt2.pivot_table(values=\"IS\", index = [\"Display Name\", \"Network\"], columns = \"Dataset\")\n",
    "nt2 = nt2.dropna(axis = 0, how = 'any')\n",
    "nt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_context(\"paper\")\n",
    "g = sns.pairplot(nt2,\n",
    "            x_vars = [\"Proteomics\", \"Transcriptomics\", \"Phosphoproteomics\"],\n",
    "                 y_vars = [\"Proteomics\", \"Transcriptomics\", \"Phosphoproteomics\"],\n",
    "             diag_kind='hist',\n",
    "             kind='reg',\n",
    "             plot_kws={\n",
    "                 'scatter_kws': {\n",
    "                     'alpha': 0.25,\n",
    "                     'color': \"#005AB5\"\n",
    "                 },\n",
    "                 'line_kws': {\n",
    "                     'color': '#DC3220'\n",
    "                 }\n",
    "             }, diag_kws = {'color': '#005AB5'},\n",
    "             corner=False)\n",
    "g.savefig(\"relation_between_importance_scores.png\", dpi = 300)\n",
    "g.savefig(\"relation_between_importance_scores.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import spearmanr, pearsonr\n",
    "print(spearmanr(nt2.Transcriptomics, nt2.Proteomics), pearsonr(nt2.Transcriptomics, nt2.Proteomics))\n",
    "print(spearmanr(nt2.Transcriptomics, nt2.Phosphoproteomics), pearsonr(nt2.Transcriptomics, nt2.Phosphoproteomics))\n",
    "print(spearmanr(nt2.Phosphoproteomics, nt2.Proteomics), pearsonr(nt2.Phosphoproteomics, nt2.Proteomics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "commonNodesRules = df[df.nodeList.isin(\n",
    "    nt2.index.get_level_values('Display Name').tolist())]\n",
    "netid_to_name = {\n",
    "    key: value\n",
    "    for (key, value) in\n",
    "    zip(set(nt2.index.get_level_values('Network')),\n",
    "        [getPathwayName(f) for f in set(nt2.index.get_level_values('Network'))])\n",
    "}\n",
    "nt2['networkName'] = [netid_to_name[i] for i in nt2.index.get_level_values('Network')]\n",
    "commonNodesRules = commonNodesRules[commonNodesRules.networkName.isin(\n",
    "    nt2.networkName)].reset_index(drop=True)\n",
    "commonNodesRules.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnr_transcriptomics = commonNodesRules[\n",
    "    commonNodesRules['methodName'].str.contains('Transcriptomics')]\n",
    "print(cnr_transcriptomics.shape)\n",
    "cnr_phosphoproteomics = commonNodesRules[\n",
    "    commonNodesRules['methodName'].str.contains('Phosphoproteomics')]\n",
    "print(cnr_phosphoproteomics.shape)\n",
    "cnr_proteomics = commonNodesRules[commonNodesRules['methodName'].str.match(\n",
    "    'Proteomics'\n",
    ")]  #note difference between contains and match - DO NOT CHANGE THIS\n",
    "print(cnr_proteomics.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tallyDF_final = commonNodesRules\n",
    "tallyDF_final[\"percentOverlap\"] = [np.nan for i in range(0, tallyDF_final.shape[0])]\n",
    "print(tallyDF_final.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def percentOverlap2(equivs, exactCompare=False):\n",
    "    \"\"\"Compare n lists to get a percentage overlap compared to the \"universe\" (i.e. the union of all n lists)\"\"\"\n",
    "    overlap = set()\n",
    "    universe = set()\n",
    "    for l in equivs:\n",
    "        rule = set([tuple(i) for i in l])\n",
    "        universe = universe | rule\n",
    "        if len(overlap) == 0:\n",
    "            overlap = rule\n",
    "        else:\n",
    "            overlap = rule & overlap\n",
    "    if len(universe) == 0:\n",
    "        return(np.nan)\n",
    "    else:\n",
    "        if exactCompare:\n",
    "            percentOverlap = float(len(overlap)) / len(universe) *100\n",
    "        else:\n",
    "            if len(overlap) > 0:\n",
    "                return(float(1))\n",
    "            else:\n",
    "                return(float(0))\n",
    "    return(percentOverlap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNodeMinimalRule(ruleSet, andNodeList):\n",
    "    numOrRules = [sum(ruleSet[j]) for j in range(len(ruleSet))]\n",
    "    deciderVar = max(numOrRules)  # maximal or rules\n",
    "    maxOrRules = ruleSet[\n",
    "        numOrRules.index(deciderVar)\n",
    "    ]  # rules with maximum or terms\n",
    "    maxUpstreamNodes = 0\n",
    "    minimalRule = []\n",
    "    for orRule in [maxOrRules]:\n",
    "        if sum(orRule) > 0:\n",
    "            numUpstreamNodes = [\n",
    "                andNodeList[orTerm]\n",
    "                for orTerm in range(len(orRule))\n",
    "                if orRule[orTerm] == 1\n",
    "            ]\n",
    "        else:\n",
    "            minimalRule = orRule\n",
    "            continue\n",
    "        numUpstreamNodes = [len(element) for element in numUpstreamNodes]\n",
    "        numUpstreamNodes = sum(numUpstreamNodes)\n",
    "        if numUpstreamNodes > maxUpstreamNodes:\n",
    "            maxUpstreamNodes = numUpstreamNodes\n",
    "            minimalRule = orRule\n",
    "        else:\n",
    "            maxUpstreamNodes = maxUpstreamNodes\n",
    "            minimalRule = minimalRule\n",
    "    return minimalRule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for network in list(set(commonNodesRules.networkName))[0:15]:\n",
    "    print(\"############\")\n",
    "    print(network.upper())\n",
    "    print(\"######\\n\")\n",
    "    net_trans = cnr_transcriptomics[\n",
    "        cnr_transcriptomics['networkName'].str.contains(network, regex=False)]\n",
    "    net_phosph = cnr_phosphoproteomics[\n",
    "        cnr_phosphoproteomics['networkName'].str.contains(network,\n",
    "                                                          regex=False)]\n",
    "    net_prot = cnr_proteomics[cnr_proteomics['networkName'].str.contains(\n",
    "        network, regex=False)]\n",
    "    allNodes = pd.concat(\n",
    "        [net_trans.nodeList, net_phosph.nodeList, net_prot.nodeList])\n",
    "    for node in set(allNodes):\n",
    "\n",
    "        tempTrans = pd.DataFrame(net_trans[net_trans[\"nodeList\"] == node])\n",
    "        tempProt = pd.DataFrame(net_prot[net_prot[\"nodeList\"] == node])\n",
    "        tempPhosph = pd.DataFrame(net_phosph[net_phosph[\"nodeList\"] == node])\n",
    "        #print(tempTrans.shape, tempPhosph.shape, tempProt.shape)\n",
    "        \"\"\"\n",
    "        percentOverlap = percentOverlap2([\n",
    "            tempTrans.plainRules.tolist(),\n",
    "            tempProt.plainRules.tolist(),\n",
    "            tempPhosph.plainRules.tolist()\n",
    "        ])\n",
    "        if percentOverlap != 1:\n",
    "            print(node, network)\n",
    "            print([\n",
    "                set(tempTrans.plainRules.tolist()),\n",
    "                set(tempProt.plainRules.tolist()),\n",
    "                set(tempPhosph.plainRules.tolist())\n",
    "            ], percentOverlap)\n",
    "        \"\"\"\n",
    "        minimalTrans = getNodeMinimalRule(\n",
    "            literal_eval(tempTrans.equivs.iloc[0]),\n",
    "            literal_eval(tempTrans.andNodeList.iloc[0]))\n",
    "        minimalTrans = literal_eval(tempTrans.plainRules.iloc[0])[literal_eval(\n",
    "            tempTrans.equivs.iloc[0]).index(minimalTrans)]\n",
    "        minimalProt = getNodeMinimalRule(\n",
    "            literal_eval(tempProt.equivs.iloc[0]),\n",
    "            literal_eval(tempProt.andNodeList.iloc[0]))\n",
    "        minimalProt = literal_eval(tempProt.plainRules.iloc[0])[literal_eval(\n",
    "            tempProt.equivs.iloc[0]).index(minimalProt)]\n",
    "        minimalPhosph = getNodeMinimalRule(\n",
    "            literal_eval(tempPhosph.equivs.iloc[0]),\n",
    "            literal_eval(tempPhosph.andNodeList.iloc[0]))\n",
    "        minimalPhosph = literal_eval(tempPhosph.plainRules.iloc[0])[literal_eval(\n",
    "            tempPhosph.equivs.iloc[0]).index(minimalPhosph)]\n",
    "        print(node)\n",
    "        print(\"Trans: \", minimalTrans, \"\\nProt:\", minimalProt, \"\\nPhosph:\",\n",
    "              minimalPhosph)\n",
    "        print(\"######\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minimalTrans = \"RB1*=(CDKN1A) or (CDK2 and CDKN1A) or (CDK2)\"\n",
    "minimalProt = \"RB1*=(GRB2) or (TP53 and CDK2 and GRB2) or (TP53 and CDK2) or (TP53 and GRB2) or (TP53) or (CDK2 and GRB2) or (CDK2)\"\n",
    "minimalPhosph = \"RB1*=(not PTK2B) or (not TP53 and  not MAP3K7 and  not PTK2B) or (not TP53 and  not MAP3K7) or (not TP53) or (not MAP3K7 and  not PTK2B) or (not MAP3K7)\"\n",
    "\n",
    "# simple intersection\n",
    "def makeRuleList(rule):\n",
    "    line=rule\n",
    "    line=line.strip()\n",
    "    matcher=re.search(\"(.*)\\*=(.*)\", line)\n",
    "    node=matcher.group(1).strip()\n",
    "    rule=matcher.group(2).strip()\n",
    "    preds=re.sub(\"and|not|or|\\(|\\)\", \"\", rule)\n",
    "    preds=preds.strip()\n",
    "    preds=re.sub(\"\\s+\", \",\", preds)\n",
    "    preds=tuple(preds.split(\",\"))\n",
    "    rule=rule.split(\" or \")\n",
    "    return rule, preds\n",
    "    \n",
    "transRule, transPreds = makeRuleList(minimalTrans)\n",
    "protRule, protPreds = makeRuleList(minimalProt)\n",
    "phosphRule, phosphPreds = makeRuleList(minimalPhosph)\n",
    "\n",
    "print(set(transRule),set(protRule),set(phosphRule))\n",
    "print(set(transRule) & set(protRule) & set(phosphRule))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(transRule).union(set(protRule)).union(set(phosphRule))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import Get_expanded_network\n",
    "Get_expanded_network([literal_eval(t)[0] for t in net_trans.plainRules.tolist()], equal_sign=\"*=\").nodes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for network in list(set(commonNodesRules.networkName)):\n",
    "    net_trans = cnr_transcriptomics[cnr_transcriptomics['networkName'].str.contains(network, regex=False)]\n",
    "    net_phosph = cnr_phosphoproteomics[cnr_phosphoproteomics['networkName'].str.contains(network, regex=False)]\n",
    "    net_prot = cnr_proteomics[cnr_proteomics['networkName'].str.contains(network, regex=False)]\n",
    "    print(net_trans.shape)\n",
    "    for node in set(df.nodeList):\n",
    "        tempTrans = pd.DataFrame(net_trans[net_trans[\"nodeList\"] == node])\n",
    "        tempProt = pd.DataFrame(net_prot[net_prot[\"nodeList\"] == node])\n",
    "        tempPhosph = pd.DataFrame(net_phosph[net_phosph[\"nodeList\"] == node])\n",
    "        if (net_trans.shape[0] >= 0 and net_prot.shape[0] >= 0 and net_phosph.shape[0]>= 0):\n",
    "            percentOverlap = percentOverlap2([tempTrans.plainRules.tolist(), tempProt.plainRules.tolist(), tempPhosph.plainRules.tolist()])\n",
    "            temp2 = [t1 & t2 for t1, t2 in zip(list(tallyDF_final[\"networkName\"]== network), list(tallyDF_final[\"nodeList\"] == node))]\n",
    "            tallyDF_final.loc[temp2, \"percentOverlap\"] = percentOverlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tallyDF_final.head()\n",
    "tallyDF_final.to_csv(\"tallyDF.csv\")\n",
    "\"\"\"Aggregate by network and show average percent overlap\"\"\"\n",
    "temp1 = pd.DataFrame(tallyDF_final.groupby([\"networkName\"]).mean())\n",
    "temp1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (anaconda3 2020.07)",
   "language": "python",
   "name": "anaconda3-2020.07"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
